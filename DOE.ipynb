{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637e6d38",
   "metadata": {},
   "source": [
    "# Optimization of reactor output\n",
    "This script uses real weather data between 2013 and 2020 to simulate plant output as a function of wind turbines, solar panels, battery size, and three control parameters that change the battery set point based on forecasted energy production. Multiple simulations structured as a DOE are run for different scenarios, and a model is generated to predict the profit as a function of the aforementioned factors. Finally, this model is optimized to find the most profitable configuration for the plant.\n",
    "\n",
    "The code below is also contained in long_term_output.py. They are duplicated in this Jupyter notebook to take the user step-by-step through the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4a4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doe_functions as doef\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05928c0d",
   "metadata": {},
   "source": [
    "The first pass at the DOE is below. Note that all features are 3 levels except for the wind turbine (wt). This is because some  research suggests 1MW is one of the smallest standard sizes for wind turbines, and that this is quite expensive and powerful relative to our purposes. We effectively structure the DOE as if this is a binary variable and we do a full factorial plus a Box-Behnken design at both levels of the wind turbine feature. When analyzing later, however, this variable will be categorized as continuous to allow the model to signal to us if a smaller wind turbine is optimal (quick research suggests that smaller wind turbines do exist, although their availability is unclear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76100238",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"wt_list\" : [0, 1], # number of 1MW wind turbines\n",
    "    \"sp_list\" : [5000, 10000, 15000], # area in m2 of solar panels\n",
    "    \"b_list\" : [516, 1144, 2288], # battery sizes in kW\n",
    "    \"c1_list\" : [0, 1, 2], # constants for battery setpoint eqn\n",
    "    \"c2_list\" : [0, 1, 2],\n",
    "    \"c3_list\" : [-1, 0, 1]\n",
    "    }\n",
    "\n",
    "# DOE input is a 2-level full factorial plus a Box-Behnken to capture curvature\n",
    "doe = pd.read_excel(\"DOE.xlsx\")\n",
    "\n",
    "# Run DOE\n",
    "doe_results, forecast_store = doef.run_doe(doe, parameters, show_run_status = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af4ffa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt_level</th>\n",
       "      <th>sp_level</th>\n",
       "      <th>b_level</th>\n",
       "      <th>c1_level</th>\n",
       "      <th>c2_level</th>\n",
       "      <th>c3_level</th>\n",
       "      <th>profit</th>\n",
       "      <th>revenue</th>\n",
       "      <th>opex</th>\n",
       "      <th>capex</th>\n",
       "      <th>total_sx</th>\n",
       "      <th>e_to_grid</th>\n",
       "      <th>e_from_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59098.402663</td>\n",
       "      <td>344256.415447</td>\n",
       "      <td>142648.921875</td>\n",
       "      <td>142509.090909</td>\n",
       "      <td>286880.346206</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.564766e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46757.833526</td>\n",
       "      <td>323337.803426</td>\n",
       "      <td>134070.878991</td>\n",
       "      <td>142509.090909</td>\n",
       "      <td>269448.169522</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.290268e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43315.597330</td>\n",
       "      <td>318047.905667</td>\n",
       "      <td>132223.217428</td>\n",
       "      <td>142509.090909</td>\n",
       "      <td>265039.921389</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.231143e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36176.131643</td>\n",
       "      <td>303454.130041</td>\n",
       "      <td>124768.907488</td>\n",
       "      <td>142509.090909</td>\n",
       "      <td>252878.441701</td>\n",
       "      <td>3.981881e-11</td>\n",
       "      <td>3.992605e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49798.300094</td>\n",
       "      <td>326294.839646</td>\n",
       "      <td>133987.448643</td>\n",
       "      <td>142509.090909</td>\n",
       "      <td>271912.366371</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.287598e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wt_level  sp_level  b_level  c1_level  c2_level  c3_level        profit  \\\n",
       "0         0         0        0         0         0         0  59098.402663   \n",
       "1         0         0        0         0         0         2  46757.833526   \n",
       "2         0         0        0         0         2         0  43315.597330   \n",
       "3         0         0        0         0         2         2  36176.131643   \n",
       "4         0         0        0         2         0         0  49798.300094   \n",
       "\n",
       "         revenue           opex          capex       total_sx     e_to_grid  \\\n",
       "0  344256.415447  142648.921875  142509.090909  286880.346206  0.000000e+00   \n",
       "1  323337.803426  134070.878991  142509.090909  269448.169522  0.000000e+00   \n",
       "2  318047.905667  132223.217428  142509.090909  265039.921389  0.000000e+00   \n",
       "3  303454.130041  124768.907488  142509.090909  252878.441701  3.981881e-11   \n",
       "4  326294.839646  133987.448643  142509.090909  271912.366371  0.000000e+00   \n",
       "\n",
       "    e_from_grid  \n",
       "0  4.564766e+06  \n",
       "1  4.290268e+06  \n",
       "2  4.231143e+06  \n",
       "3  3.992605e+06  \n",
       "4  4.287598e+06  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doe_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa0db8",
   "metadata": {},
   "source": [
    "## Fitting a model to the DOE\n",
    "We use polynomial regression to fit a model of degree 2 with interactions to the DOE results. In the function below, we also include the ability to eliminate all higher-order terms of a specific feature. This will come in useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e5fbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 profit   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.997\n",
      "Method:                 Least Squares   F-statistic:                     2076.\n",
      "Date:                Thu, 10 Aug 2023   Prob (F-statistic):          1.02e-145\n",
      "Time:                        12:03:52   Log-Likelihood:                -1742.1\n",
      "No. Observations:                 146   AIC:                             3538.\n",
      "Df Residuals:                     119   BIC:                             3619.\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "1                  1.045e+05    2.1e+04      4.978      0.000    6.29e+04    1.46e+05\n",
      "wt_level           1.859e+05   1979.158     93.935      0.000    1.82e+05     1.9e+05\n",
      "sp_level           4.047e+05   1.92e+04     21.097      0.000    3.67e+05    4.43e+05\n",
      "b_level           -5.378e+04   1.92e+04     -2.804      0.006   -9.18e+04   -1.58e+04\n",
      "c1_level          -3.447e+04   1.92e+04     -1.797      0.075   -7.25e+04    3506.597\n",
      "c2_level          -5.318e+04   1.92e+04     -2.772      0.006   -9.12e+04   -1.52e+04\n",
      "c3_level          -3.375e+04   1.92e+04     -1.759      0.081   -7.17e+04    4236.143\n",
      "wt_level^2         3.718e+05   3958.315     93.935      0.000    3.64e+05     3.8e+05\n",
      "wt_level sp_level -2.574e+05   4160.416    -61.857      0.000   -2.66e+05   -2.49e+05\n",
      "wt_level b_level   2.348e+04   4160.416      5.644      0.000    1.52e+04    3.17e+04\n",
      "wt_level c1_level  1.108e+04   4160.416      2.664      0.009    2846.326    1.93e+04\n",
      "wt_level c2_level  1.551e+04   4160.416      3.727      0.000    7267.244    2.37e+04\n",
      "wt_level c3_level  1.127e+04   4160.416      2.709      0.008    3034.250    1.95e+04\n",
      "sp_level^2         3.399e+04   7762.014      4.379      0.000    1.86e+04    4.94e+04\n",
      "sp_level b_level  -1.202e+04   4804.035     -2.503      0.014   -2.15e+04   -2509.936\n",
      "sp_level c1_level -5061.0005   4804.035     -1.053      0.294   -1.46e+04    4451.468\n",
      "sp_level c2_level -7042.2467   4804.035     -1.466      0.145   -1.66e+04    2470.222\n",
      "sp_level c3_level -4602.4481   4804.035     -0.958      0.340   -1.41e+04    4910.021\n",
      "b_level^2         -2.677e+04   7762.014     -3.449      0.001   -4.21e+04   -1.14e+04\n",
      "b_level c1_level  -2795.9097   4804.035     -0.582      0.562   -1.23e+04    6716.559\n",
      "b_level c2_level  -8975.4976   4804.035     -1.868      0.064   -1.85e+04     536.971\n",
      "b_level c3_level  -3381.0716   4804.035     -0.704      0.483   -1.29e+04    6131.397\n",
      "c1_level^2         6018.8100   7762.014      0.775      0.440   -9350.752    2.14e+04\n",
      "c1_level c2_level  4735.4967   4804.035      0.986      0.326   -4776.972    1.42e+04\n",
      "c1_level c3_level  4279.5129   4804.035      0.891      0.375   -5232.956    1.38e+04\n",
      "c2_level^2         1.314e+04   7762.014      1.693      0.093   -2231.142    2.85e+04\n",
      "c2_level c3_level  5238.8159   4804.035      1.091      0.278   -4273.653    1.48e+04\n",
      "c3_level^2         4901.5132   7762.014      0.631      0.529   -1.05e+04    2.03e+04\n",
      "==============================================================================\n",
      "Omnibus:                        8.570   Durbin-Watson:                   0.873\n",
      "Prob(Omnibus):                  0.014   Jarque-Bera (JB):                4.352\n",
      "Skew:                          -0.192   Prob(JB):                        0.114\n",
      "Kurtosis:                       2.247   Cond. No.                     6.66e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.65e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "\n",
    "# Note that some variables have the suffix _f (for fixed) or _uf (for unfixed).\n",
    "# This indicates whether the list/array shrinks as variables are eliminated.\n",
    "\n",
    "def fit_results(doe_results, remove_var=None):\n",
    "    X_features = doe_results[[\"wt_level\", \"sp_level\", \"b_level\", \"c1_level\", \"c2_level\", \"c3_level\"]]\n",
    "    y = doe_results[\"profit\"]\n",
    "    \n",
    "    model = PolynomialFeatures(degree=2)\n",
    "    \n",
    "    fit_tr_model = model.fit_transform(X_features)\n",
    "    features = model.get_feature_names_out()\n",
    "    X = pd.DataFrame(fit_tr_model, columns=features)\n",
    "    \n",
    "    # Remove higher order terms of 'remove_var'. Leave the first order term.\n",
    "    if remove_var:\n",
    "        indicies_to_remove = []\n",
    "        for i in range(len(features)):\n",
    "            feature = features[i] \n",
    "            \n",
    "            # Searching for \" \" or \"^\" ensures only higher-order terms are removed\n",
    "            if remove_var in feature and (\" \" in feature or \"^\" in feature):\n",
    "                indicies_to_remove.append(i) \n",
    "                X.drop(columns=[feature], inplace=True)\n",
    "                    \n",
    "        features = np.delete(features, indicies_to_remove)\n",
    "    \n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(fit_tr_model, y)\n",
    "    \n",
    "    est = sm.OLS(y, X)\n",
    "    est_fit = est.fit()\n",
    "\n",
    "    return X, y, est_fit, features\n",
    "\n",
    "X, y, est_fit, feature_names = fit_results(doe_results)\n",
    "\n",
    "print(\"Initial results:\")\n",
    "print(est_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca7a75",
   "metadata": {},
   "source": [
    "## Feature elimination\n",
    "In the initial results we see that there are there are some features with a low p-value (< 0.05), and others with high p-values (> 0.05). In order to create a better-fitting model, we will eliminate the insignificant features one by one in a process called *backward elimination*.\n",
    "\n",
    "This is an iterative process in which the feature with the highest eligible p-value is removed and the model is re-run until all features have a significant p-value or are uneligible for removal. A feature is uneligible for removal if:\n",
    "* It is a first-order feature and there are higher-order features still in the model that contain the first-order feature.\n",
    "* It is an interaction term and there are higher-order features still in the model that contain one of the features present in the interaction.\n",
    "\n",
    "In order to check whether a feature is eligible when doing backward elimination, we first make a boolean matrix with each feature in the model, where a row reads True if the corresponding feature is a lower-order feature of the feature in the column. A feature will only be eligible if the matrix reads False for all features still in the model.\n",
    "\n",
    "Note that higher-order features are identified by searching for the carrot \"^\" symbol, and reactions by looking for the space \" \" as this is the convention that sklearn.preprocessing.PolynomialFeatures uses when naming the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5425ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(a, b):\n",
    "    for i in range(len(a)):\n",
    "       if a[i] == b:\n",
    "           return i\n",
    "\n",
    "# Create boolean array that indicates thes lower order terms for each term in the model\n",
    "def make_lot_array(feature_names):\n",
    "    lower_order_terms = np.full((len(feature_names), len(feature_names)), False)\n",
    "\n",
    "    for i in range(len(feature_names)):\n",
    "        feature = feature_names[i]\n",
    "        \n",
    "        # find 1st order terms for squared features\n",
    "        if \"^\" in feature:\n",
    "            first_order_term = re.search(\"^[a-z0-9_]*\", feature).group(0)  \n",
    "            first_order_term_index = get_index(feature_names, first_order_term)\n",
    "            lower_order_terms[i, first_order_term_index] = True\n",
    "                \n",
    "        # find 1st order terms for interactions\n",
    "        if \" \" in feature:\n",
    "            first_order_term1 = re.search(\"^[a-z0-9_]*\", feature).group(0)\n",
    "            first_order_term2 = re.search(\"[a-z0-9_]*$\", feature).group(0)      \n",
    "            first_order_term1_index = get_index(feature_names, first_order_term1)\n",
    "            first_order_term2_index = get_index(feature_names, first_order_term2)\n",
    "            lower_order_terms[i, first_order_term1_index] = True\n",
    "            lower_order_terms[i, first_order_term2_index] = True\n",
    "            \n",
    "            # find interactions that contain a 1st order term also present in squared term\n",
    "            feature1_squared = first_order_term1 + \"^2\"\n",
    "            feature2_squared = first_order_term2 + \"^2\"\n",
    "            feature1_squared_index = get_index(feature_names, feature1_squared)\n",
    "            feature2_squared_index = get_index(feature_names, feature2_squared)\n",
    "            lower_order_terms[feature1_squared_index, i] = True\n",
    "            lower_order_terms[feature2_squared_index, i] = True\n",
    "            \n",
    "    return lower_order_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc7a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes highest p-value terms one at a time, if no higher-order terms exist,\n",
    "# until all (elegible) terms have a p-value of < 0.05\n",
    "def backward_elimination(est_fit, X, y, feature_names):\n",
    "    pvals = est_fit.pvalues\n",
    "    \n",
    "    lower_order_terms_f = make_lot_array(feature_names)\n",
    "    inds_of_remaining_terms = list(range(len(feature_names)))\n",
    "\n",
    "    # Matches index to feature in lower_order_terms_f\n",
    "    feature_index_dict_f = {feature_names[i]:i for i in range(len(feature_names))}\n",
    "\n",
    "    feature_names_uf = feature_names\n",
    "    \n",
    "    while max(pvals[1:]) > 0.05:\n",
    "\n",
    "        highest_pval_index = np.argmax(pvals[1:]) + 1\n",
    "        feature_to_remove = feature_names_uf[highest_pval_index]\n",
    "        feature_index = feature_index_dict_f[feature_to_remove]\n",
    "        \n",
    "        if not any(lower_order_terms_f[inds_of_remaining_terms, feature_index]):\n",
    "            X.drop(columns=[feature_to_remove], inplace=True)\n",
    "            feature_names_uf = np.delete(feature_names_uf, highest_pval_index)\n",
    "            inds_of_remaining_terms[feature_index] = 0\n",
    "            \n",
    "            est_fit = sm.OLS(y, X).fit()\n",
    "            pvals = est_fit.pvalues\n",
    "        else:\n",
    "            pvals[highest_pval_index] = 0\n",
    "        \n",
    "    return est_fit, feature_names_uf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9cef25",
   "metadata": {},
   "source": [
    "## Generate a model for profit as a function of the input parameters\n",
    "Finally, we generate the model by running fit_results and backward_elimination in series, and then extracting the coeficients from the model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1dcf2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 profit   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.997\n",
      "Method:                 Least Squares   F-statistic:                     2367.\n",
      "Date:                Thu, 10 Aug 2023   Prob (F-statistic):          2.44e-150\n",
      "Time:                        12:03:52   Log-Likelihood:                -1743.3\n",
      "No. Observations:                 146   AIC:                             3535.\n",
      "Df Residuals:                     122   BIC:                             3606.\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "1                  9.847e+04   2.03e+04      4.854      0.000    5.83e+04    1.39e+05\n",
      "wt_level           1.859e+05   1970.751     94.336      0.000    1.82e+05     1.9e+05\n",
      "sp_level           4.008e+05   1.88e+04     21.355      0.000    3.64e+05    4.38e+05\n",
      "b_level           -5.761e+04   1.88e+04     -3.069      0.003   -9.48e+04   -2.05e+04\n",
      "c1_level          -1.816e+04   1.01e+04     -1.789      0.000   -3.82e+04    1930.721\n",
      "c2_level          -5.701e+04   1.88e+04     -3.037      0.003   -9.42e+04   -1.99e+04\n",
      "c3_level          -1.966e+04   1.01e+04     -1.938      0.000   -3.98e+04     425.673\n",
      "wt_level^2         3.718e+05   3941.501     94.336      0.000    3.64e+05     3.8e+05\n",
      "wt_level sp_level -2.574e+05   4142.744    -62.121      0.000   -2.66e+05   -2.49e+05\n",
      "wt_level b_level   2.348e+04   4142.744      5.668      0.000    1.53e+04    3.17e+04\n",
      "wt_level c1_level  1.108e+04   4142.744      2.676      0.008    2883.391    1.93e+04\n",
      "wt_level c2_level  1.551e+04   4142.744      3.743      0.000    7304.308    2.37e+04\n",
      "wt_level c3_level  1.127e+04   4142.744      2.721      0.007    3071.314    1.95e+04\n",
      "sp_level^2          3.59e+04   7524.187      4.772      0.000     2.1e+04    5.08e+04\n",
      "sp_level b_level  -1.202e+04   4783.629     -2.513      0.013   -2.15e+04   -2552.734\n",
      "sp_level c1_level -5061.0005   4783.629     -1.058      0.000   -1.45e+04    4408.670\n",
      "sp_level c2_level -7042.2467   4783.629     -1.472      0.000   -1.65e+04    2427.424\n",
      "sp_level c3_level -4602.4481   4783.629     -0.962      0.000   -1.41e+04    4867.223\n",
      "b_level^2         -2.486e+04   7524.187     -3.304      0.001   -3.98e+04   -9964.316\n",
      "b_level c1_level  -2795.9097   4783.629     -0.584      0.000   -1.23e+04    6673.761\n",
      "b_level c2_level  -8975.4976   4783.629     -1.876      0.000   -1.84e+04     494.173\n",
      "b_level c3_level  -3381.0716   4783.629     -0.707      0.000   -1.29e+04    6088.599\n",
      "c1_level c2_level  4735.4967   4783.629      0.990      0.000   -4734.174    1.42e+04\n",
      "c2_level^2         1.505e+04   7524.187      2.001      0.048     158.142    2.99e+04\n",
      "c2_level c3_level  5238.8159   4783.629      1.095      0.000   -4230.855    1.47e+04\n",
      "==============================================================================\n",
      "Omnibus:                        5.674   Durbin-Watson:                   0.899\n",
      "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                3.350\n",
      "Skew:                          -0.166   Prob(JB):                        0.187\n",
      "Kurtosis:                       2.336   Cond. No.                     7.69e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.06e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Generate a pd.Series of coefficients for only the significant factors and \n",
    "# their 1st-order terms\n",
    "def generate_sig_model(doe_results, remove_var=None):\n",
    "    \n",
    "    X, y, est_fit, feature_names = fit_results(doe_results, remove_var=remove_var)  \n",
    "    est_sig_fit, feature_names = backward_elimination(est_fit, X, y, feature_names)\n",
    "    \n",
    "    coefs = est_sig_fit.params\n",
    "    \n",
    "    print(est_sig_fit.summary())\n",
    "    \n",
    "    return coefs\n",
    "\n",
    "coefs = generate_sig_model(doe_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625d067",
   "metadata": {},
   "source": [
    "# Optimize\n",
    "The function below optimizes the model using gurobi. Special care is taken to consider square terms and interactions so that they are constrained to equal the product of their first-order components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd9fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = 1.0\n",
      "wt_level = 2.0\n",
      "sp_level = 0.0\n",
      "b_level = 0.0\n",
      "c1_level = 2.0\n",
      "c2_level = 2.0\n",
      "c3_level = 2.0\n",
      "wt_level^2 = 4.0\n",
      "wt_level sp_level = 0.0\n",
      "wt_level b_level = 0.0\n",
      "wt_level c1_level = 4.0\n",
      "wt_level c2_level = 4.0\n",
      "wt_level c3_level = 4.0\n",
      "sp_level^2 = 0.0\n",
      "sp_level b_level = 0.0\n",
      "sp_level c1_level = 0.0\n",
      "sp_level c2_level = 0.0\n",
      "sp_level c3_level = 0.0\n",
      "b_level^2 = 0.0\n",
      "b_level c1_level = 0.0\n",
      "b_level c2_level = 0.0\n",
      "b_level c3_level = 0.0\n",
      "c1_level c2_level = 4.0\n",
      "c2_level^2 = 4.0\n",
      "c2_level c3_level = 4.0\n",
      "objective value:  2019496.3903095562\n"
     ]
    }
   ],
   "source": [
    "#%% Create Gurobi model to optimize DOE results\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create Gurobi environment and suppress output\n",
    "env = gp.Env(empty=True)\n",
    "env.setParam(\"OutputFlag\", 0)\n",
    "env.start()\n",
    "\n",
    "# Optimizes model based on the series of coefficients for each factor.\n",
    "# Returns a Gurobi Model object and prints the optimal factor values\n",
    "def optimize_model(coefs):\n",
    "    model = gp.Model(env=env)\n",
    "    model.setParam('NonConvex', 2) # To allow for quadratic equality constraints\n",
    "    \n",
    "    factors_dict = {}\n",
    "    \n",
    "    # Create gurobi variables\n",
    "    for factor in coefs.index:\n",
    "        if '^' not in factor and ' ' not in factor:\n",
    "            factors_dict[factor] = model.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=2, name=factor)\n",
    "        else:\n",
    "            factors_dict[factor] = model.addVar(vtype=GRB.CONTINUOUS, name=factor)\n",
    "    \n",
    "    # Add equality constraints\n",
    "    for f in factors_dict:\n",
    "        if f == '1': # Must maintain constant term, constrain this to 1\n",
    "            factor = factors_dict[f]\n",
    "            model.addConstr(factor == 1)\n",
    "        if '^' in f: # Squared terms must be equal to the square of the first-order term\n",
    "            first_order_f = re.search(\"^[a-z0-9_]*\", str(f)).group(0) \n",
    "            first_order_factor = factors_dict[first_order_f]\n",
    "            factor = factors_dict[f]\n",
    "            model.addConstr(factor == first_order_factor**2)\n",
    "        if ' ' in f: # Interaction terms must be the product of the first-order terms\n",
    "            first_order_f1 = re.search(\"^[a-z0-9_]*\", str(f)).group(0)\n",
    "            first_order_f2 = re.search(\"[a-z0-9_]*$\", str(f)).group(0)\n",
    "            first_order_factor1 = factors_dict[first_order_f1]\n",
    "            first_order_factor2 = factors_dict[first_order_f2]\n",
    "            factor = factors_dict[f]\n",
    "            model.addConstr(factor == first_order_factor1 * first_order_factor2)\n",
    "            \n",
    "    # Objective function\n",
    "    model.setObjective(gp.quicksum(coefs[factor]*factors_dict[factor] for factor in factors_dict),\n",
    "                        GRB.MAXIMIZE)    \n",
    "    \n",
    "    model.optimize()\n",
    "    \n",
    "    for var in model.getVars():\n",
    "        print(var.varName, '=', var.x)\n",
    "    print('objective value: ', model.objVal)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = optimize_model(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7c681",
   "metadata": {},
   "source": [
    "As the scaled values range from 0 to 2, it can be seen in the results that the optimal model is at a corner point, so the DOE is re-run below with new parameter values. The wind turbine number is set to 1, as the results of the first DOE indicate that 1 wind turbine is better than 0. Because they're so expensive, it is assumed that a 2nd wind turbine isn't an option. Because of this, the size of the DOE can be reduced to eliminate wt = 0. The new DOE design is saved in DOE2.xlsx. The other parameters are adjusted to be centered around their previous optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7108981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 profit   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                     2903.\n",
      "Date:                Thu, 10 Aug 2023   Prob (F-statistic):           4.64e-77\n",
      "Time:                        12:12:47   Log-Likelihood:                -719.29\n",
      "No. Observations:                  73   AIC:                             1469.\n",
      "Df Residuals:                      58   BIC:                             1503.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "1                  1.754e+06   2937.099    597.021      0.000    1.75e+06    1.76e+06\n",
      "wt_level          -1.959e-11   1.64e-12    -11.936      0.000   -2.29e-11   -1.63e-11\n",
      "sp_level           3.792e+05   3242.841    116.921      0.000    3.73e+05    3.86e+05\n",
      "b_level           -2.458e+04   3242.841     -7.579      0.000   -3.11e+04   -1.81e+04\n",
      "c1_level           2193.7130   1427.138      1.537      0.000    -663.014    5050.440\n",
      "c2_level           2283.3238   1427.138      1.600      0.000    -573.403    5140.051\n",
      "c3_level            563.1510   1427.138      0.395      0.000   -2293.576    3419.878\n",
      "sp_level^2        -1.349e+05   1322.691   -101.965      0.000   -1.38e+05   -1.32e+05\n",
      "sp_level b_level   8557.8730    860.597      9.944      0.000    6835.202    1.03e+04\n",
      "sp_level c1_level -1576.0632    860.597     -1.831      0.000   -3298.734     146.608\n",
      "sp_level c2_level -1434.2750    860.597     -1.667      0.000   -3156.946     288.396\n",
      "sp_level c3_level  -463.4791    860.597     -0.539      0.000   -2186.150    1259.192\n",
      "b_level^2         -1.901e+04   1322.691    -14.373      0.000   -2.17e+04   -1.64e+04\n",
      "b_level c1_level   1573.4110    860.597      1.828      0.000    -149.260    3296.082\n",
      "b_level c2_level   1195.2851    860.597      1.389      0.000    -527.386    2917.956\n",
      "b_level c3_level    602.9768    860.597      0.701      0.000   -1119.694    2325.648\n",
      "==============================================================================\n",
      "Omnibus:                        8.827   Durbin-Watson:                   1.642\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):               11.036\n",
      "Skew:                          -0.514   Prob(JB):                      0.00401\n",
      "Kurtosis:                       4.603   Cond. No.                     3.06e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.95e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "1 = 1.0\n",
      "wt_level = 0.0\n",
      "sp_level = 1.3833421117567846\n",
      "b_level = 3.282985090303732e-13\n",
      "c1_level = 1.9999999998245572\n",
      "c2_level = 1.9999999999920974\n",
      "c3_level = 3.0316911480498244e-11\n",
      "sp_level^2 = 1.9136353981597203\n",
      "sp_level b_level = 4.541491527686803e-13\n",
      "sp_level c1_level = 2.7666842232708717\n",
      "sp_level c2_level = 2.766684223502637\n",
      "sp_level c3_level = 4.193866034937595e-11\n",
      "b_level^2 = 1.0777991103156605e-25\n",
      "b_level c1_level = 6.565970180031488e-13\n",
      "b_level c2_level = 6.56597018058152e-13\n",
      "b_level c3_level = 9.952996837453378e-24\n",
      "objective value:  2020552.7165527334\n"
     ]
    }
   ],
   "source": [
    "parameters2 = {\n",
    "    \"wt_list\" : [1], # number of 1MW wind turbines\n",
    "    \"sp_list\" : [2000, 5000, 8000], # area in m2 of solar panels\n",
    "    \"b_list\" : [263, 516, 1144], # battery sizes in kW\n",
    "    \"c1_list\" : [1, 2, 3], # constants for battery setpoint eqn\n",
    "    \"c2_list\" : [1, 2, 3],\n",
    "    \"c3_list\" : [0, 1, 2]\n",
    "    }\n",
    "\n",
    "# New DOE which removes the wind turbine feature and assumes it is fixed at 1\n",
    "doe2 = pd.read_excel(\"DOE2.xlsx\")\n",
    "\n",
    "# Run DOE\n",
    "doe_results2, _ = doef.run_doe(doe2, parameters2, show_run_status = False)\n",
    "\n",
    "coefs2 = generate_sig_model(doe_results2, remove_var='wt_level')\n",
    "\n",
    "model2 = optimize_model(coefs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6f6b8",
   "metadata": {},
   "source": [
    "Re-center the parameters again and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b677a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 profit   R-squared:                       0.993\n",
      "Model:                            OLS   Adj. R-squared:                  0.991\n",
      "Method:                 Least Squares   F-statistic:                     830.9\n",
      "Date:                Thu, 10 Aug 2023   Prob (F-statistic):           4.63e-62\n",
      "Time:                        12:21:43   Log-Likelihood:                -696.40\n",
      "No. Observations:                  73   AIC:                             1415.\n",
      "Df Residuals:                      62   BIC:                             1440.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "1                  1.953e+06   1773.428   1101.069      0.000    1.95e+06    1.96e+06\n",
      "wt_level          -1.373e-09    1.9e-12   -721.338      0.000   -1.38e-09   -1.37e-09\n",
      "sp_level           1.278e+05   2235.794     57.169      0.000    1.23e+05    1.32e+05\n",
      "b_level           -3.658e+04    804.680    -45.464      0.000   -3.82e+04    -3.5e+04\n",
      "c1_level            972.4400    804.680      1.208      0.000    -636.092    2580.972\n",
      "c2_level           1008.1830    804.680      1.253      0.000    -600.349    2616.715\n",
      "c3_level            212.3230    804.680      0.264      0.000   -1396.209    1820.855\n",
      "sp_level^2        -5.973e+04    900.174    -66.350      0.000   -6.15e+04   -5.79e+04\n",
      "sp_level b_level   8810.1403    608.281     14.484      0.000    7594.204       1e+04\n",
      "sp_level c1_level  -554.7103    608.281     -0.912      0.000   -1770.647     661.226\n",
      "sp_level c2_level  -576.4535    608.281     -0.948      0.000   -1792.390     639.483\n",
      "sp_level c3_level  -121.5858    608.281     -0.200      0.000   -1337.522    1094.350\n",
      "==============================================================================\n",
      "Omnibus:                        0.745   Durbin-Watson:                   1.463\n",
      "Prob(Omnibus):                  0.689   Jarque-Bera (JB):                0.322\n",
      "Skew:                          -0.132   Prob(JB):                        0.851\n",
      "Kurtosis:                       3.190   Cond. No.                     4.37e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.85e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "1 = 1.0\n",
      "wt_level = 0.0\n",
      "sp_level = 1.0490592009416608\n",
      "b_level = 1.5833148231040802e-13\n",
      "c1_level = 1.9999999999889144\n",
      "c2_level = 1.99999999998927\n",
      "c3_level = 1.9999999999489326\n",
      "sp_level^2 = 1.100525207080356\n",
      "sp_level b_level = 1.6609909831646534e-13\n",
      "sp_level c1_level = 2.0981184018716923\n",
      "sp_level c2_level = 2.0981184018720653\n",
      "sp_level c3_level = 2.098118401829749\n",
      "objective value:  2022782.7086164064\n"
     ]
    }
   ],
   "source": [
    "parameters3 = {\n",
    "    \"wt_list\" : [1], # Only the case with 1 wind turbine is considered\n",
    "    \"sp_list\" : [4000, 6500, 9000], # area in m2 of solar panels\n",
    "    \"b_list\" : [0, 263, 516], # battery sizes in kW\n",
    "    \"c1_list\" : [2, 3, 4], # constants for battery setpoint eqn\n",
    "    \"c2_list\" : [2, 3, 4],\n",
    "    \"c3_list\" : [-1, 0, 1]\n",
    "    }\n",
    "\n",
    "# DOE form doesn't change, so no new DOE is loaded\n",
    "\n",
    "# Run DOE\n",
    "doe_results3, _ = doef.run_doe(doe2, parameters3, show_run_status = False)\n",
    "\n",
    "coefs3 = generate_sig_model(doe_results3, remove_var='wt_level')\n",
    "\n",
    "model3 = optimize_model(coefs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10615be0",
   "metadata": {},
   "source": [
    "The results suggest it is optimal to have no battery. This could be reasonable, as it suggests the cost of the battery is too high to be offset by the energy from grid we must buy when renewable energy production is low. As all the constants relate to parameters for determining battery set point, they are no longer relevant in the model and will be set to 0 for the next calculation. Below, we calculate the expected results at this optimal level. Note that the optimal profit below deviates slightly from the value calculated above. This is due to the error between the actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5edf315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit (€/yr):  2014687\n",
      "Revenue (€/yr):  2304598\n",
      "Opex (€/yr):  21730\n",
      "Capex (€/yr):  268182\n",
      "Sulfur (kmol/yr):  261\n",
      "Energy sold to grid (MW/yr):  6.0\n",
      "Energy purchased from grid (MW/yr):  86.9\n"
     ]
    }
   ],
   "source": [
    "from weather_energy_components import years\n",
    "\n",
    "parameters_final = {\n",
    "    \"wt_list\" : [1], # Only the case with 1 wind turbine is considered\n",
    "    \"sp_list\" : [6500], # area in m2 of solar panels\n",
    "    \"b_list\" : [0], # battery sizes in kW\n",
    "    \"c1_list\" : [0], # constants for battery setpoint eqn\n",
    "    \"c2_list\" : [0],\n",
    "    \"c3_list\" : [0]\n",
    "    }\n",
    "\n",
    "run = pd.Series([0, 0, 0, 0, 0, 0], [\"wt_level\", \"sp_level\", \"b_level\", \"c1_level\",\n",
    "                                     \"c2_level\", \"c3_level\"])\n",
    "\n",
    "profit, revenue, opex, capex, total_sx, e_to_grid, e_from_grid \\\n",
    "    = doef.run_scenario(forecast_store, parameters_final, run)\n",
    "    \n",
    "print(\"Profit (€/yr): \", round(profit))\n",
    "print(\"Revenue (€/yr): \", round(revenue))\n",
    "print(\"Opex (€/yr): \", round(opex))\n",
    "print(\"Capex (€/yr): \", round(capex))\n",
    "print(\"Sulfur (kmol/yr): \", round(total_sx/years/1000))\n",
    "print(\"Energy sold to grid (MW/yr): \", round(e_to_grid/years/1000, 1))\n",
    "print(\"Energy purchased from grid (MW/yr): \", round(e_from_grid/years/1000, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
